# filename: crawl_fablecottage.py

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from deep_translator import GoogleTranslator
import requests
import time
import re

base_url = "https://www.thefablecottage.com"
main_url = base_url
save_api = "http://localhost:3000/api/save-crawled-story"

# ì…€ë ˆë‹ˆì›€ ì˜µì…˜
options = Options()
options.add_argument("--headless")
options.add_argument("--disable-gpu")
options.add_argument("--no-sandbox")
options.add_argument("--disable-dev-shm-usage")
driver = webdriver.Chrome(options=options)

# ì œëª© ê´„í˜¸ ì œê±°
def clean_title(title: str) -> str:
    return re.sub(r"\s*\(.*?\)", "", title).strip()

# ê¸´ í…ìŠ¤íŠ¸ë„ ì²˜ë¦¬ ê°€ëŠ¥í•œ ë²ˆì—­ í•¨ìˆ˜
def translate_long_text(text: str) -> str:
    try:
        if len(text) < 4900:
            return GoogleTranslator(source="auto", target="ko").translate(text)

        chunks = []
        paragraphs = text.split('\n')
        buffer = ""

        for para in paragraphs:
            if len(buffer) + len(para) < 4800:
                buffer += para + "\n"
            else:
                translated = GoogleTranslator(source="auto", target="ko").translate(buffer.strip())
                time.sleep(1)  # ë²ˆì—­ ë˜ëŠ” ì €ìž¥ í›„
                chunks.append(translated)
                buffer = para + "\n"

        if buffer.strip():
            translated = GoogleTranslator(source="auto", target="ko").translate(buffer.strip())
            chunks.append(translated)

        return "\n\n".join(chunks)

    except Exception as e:
        print(f"âŒ ë²ˆì—­ ì˜¤ë¥˜ (ê¸´ í…ìŠ¤íŠ¸): {e}")
        return ""

# ìŠ¤í† ë¦¬ ì €ìž¥ (ìž¬ì‹œë„ í¬í•¨)
def save_story(title_ko, content_ko):
    if not title_ko or not content_ko:
        print("âš ï¸ ì €ìž¥í•  ë°ì´í„° ë¶€ì¡±. ìŠ¤í‚µ")
        return
    try:
        res = requests.post(save_api, json={"titleKo": title_ko, "contentKo": content_ko}, timeout=10)
        if res.status_code == 200:
            print(f"âœ… ì €ìž¥ ì„±ê³µ: {title_ko}")
        else:
            print(f"âŒ 1ì°¨ ì €ìž¥ ì‹¤íŒ¨: {res.status_code} - {res.text}")
            time.sleep(1)
            # ìž¬ì‹œë„
            res = requests.post(save_api, json={"titleKo": title_ko, "contentKo": content_ko}, timeout=10)
            if res.status_code == 200:
                print(f"âœ… 2ì°¨ ì‹œë„ ì €ìž¥ ì„±ê³µ: {title_ko}")
            else:
                print(f"âŒ 2ì°¨ ì‹œë„ë„ ì‹¤íŒ¨: {res.status_code} - {res.text}")
    except Exception as e:
        print(f"âŒ ì €ìž¥ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")

# ëª©ë¡ì—ì„œ ë§í¬ ìˆ˜ì§‘
def crawl_fable_links():
    print(f"ðŸŒ í¬ë¡¤ë§ ì‹œìž‘: {main_url}")
    driver.get(main_url)

    WebDriverWait(driver, 10).until(
        EC.presence_of_element_located((By.CSS_SELECTOR, "div.index-item a.index-item-img"))
    )

    link_elements = driver.find_elements(By.CSS_SELECTOR, "div.index-item a.index-item-img")
    links = []

    for e in link_elements:
        href = e.get_attribute("href")
        if href:
            links.append(href if href.startswith("http") else base_url + href)

    print(f"ðŸ”— ìˆ˜ì§‘ëœ ë™í™” ë§í¬ ìˆ˜: {len(links)}")
    return links

# ë™í™” íŽ˜ì´ì§€ í¬ë¡¤ë§ ë° ì €ìž¥
def extract_and_save_story(link):
    print(f"\nðŸš€ ë™í™” ì ‘ì†: {link}")
    try:
        driver.get(link)
        time.sleep(2)

        title_en = driver.title.replace(" â€” Fable Cottage", "").strip()
        title_en = clean_title(title_en)
        title_ko = translate_long_text(title_en)

        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, "p")))
        paragraphs = driver.find_elements(By.TAG_NAME, "p")
        content_en = "\n".join(p.text for p in paragraphs if p.text.strip())
        content_ko = translate_long_text(content_en)

        save_story(title_ko, content_ko)

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        driver.save_screenshot("error_page.png")

# ì „ì²´ ì‹¤í–‰
def main():
    links = crawl_fable_links()
    for link in links:
        extract_and_save_story(link)
        time.sleep(3)

    driver.quit()
    print("\nðŸ ì „ì²´ í¬ë¡¤ë§ ì™„ë£Œ.")

if __name__ == "__main__":
    main()
